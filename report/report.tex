\documentclass{article}
\usepackage[british]{babel}
\usepackage{csquotes}
\usepackage{hyperref}

\usepackage[backend=biber,style=alphabetic]{biblatex}
\addbibresource{\jobname.bib}

\usepackage{acronym}
\acrodef{ACT}{auto-correlation time}
\acrodef{ESS}{effective sample size}
\acrodef{HMC}{Hamiltonian Monte Carlo}
\acrodef{MCMC}{Markov chain Monte Carlo}
\acrodef{ODE}{ordinary differential equation}

\usepackage{mathtools}
\newcommand{\dd}{\, \mathrm{d}}
\renewcommand{\vec}[1]{\ensuremath{\boldsymbol{\mathbf{#1}}}}
\newcommand{\mat}[1]{\ensuremath{\boldsymbol{\mathbf{#1}}}}
\newcommand{\op}[1]{\ensuremath{\boldsymbol{\mathbf{#1}}}}
\newcommand{\norm}{\ensuremath{\mathcal{N}}}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{caption}
\captionsetup[ruled]{labelsep=period}

\title{Implementing \acl{HMC} for Efficient Bayesian Evolutionary Analysis \\
           \Large\textsc{awc summer scholarship report}}
\author{Arman Bilge \\ \texttt{armanbilge@gmail.com}}
\date{16 April 2015}

\frenchspacing
\begin{document}

    \maketitle

    \subsection*{Introduction}

    Bayesian evolutionary analysis is centered around sampling from the
        posterior probability distribution of a phylogenetic
        tree~$\mathcal{T}$ and model parameters~$\vec\theta$
        given the molecular sequence data~$\mathcal{D}$~\cite{Bou+14},
        which by Bayes' theorem is
        \begin{equation}
            p\left(\mathcal{T}, \vec\theta \mid \mathcal{D}\right)
                \propto p\left(\mathcal{D} \mid \mathcal{T},\vec\theta\right)
                p\left(\mathcal{T} \mid \vec\theta\right) p\left(\vec\theta\right).
        \end{equation}
    Although direct sampling from this distribution is impossible,
        sampling strategies utilising \ac{MCMC} techniques have been quite
        successful~\cite{RH03,Dru+12,Bou+14}.

    The success of \ac{MCMC}

    An \ac{MCMC} method whose

    The ideal sampling algorithm maximises the number of pseudo-independent
        samples, called the \ac{ESS}, present in all of the samples drawn by
        minimising the \ac{ACT}.

    Today, the amount of molecular data available grows rapidly, as does the
        complexity of the models used to analyse them.

    \ac{HMC}, first described as hybrid Monte Carlo by \textcite{Dua+87},

    \subsection*{Methods}

    Let $\pi\left(\vec{q}\right)$ be the target probability density.
    We can consider a particle in our state space with position given
        by~$\vec{q}$ and momentum by $\vec{p}$.
    Then the Hamiltonian for our system is
        \begin{equation}
            H\left(\vec{q},\vec{p}\right)
            = U\left(\vec{q}\right) + K\left(\vec{p}\right)
        \end{equation}
        with the potential energy
        $U\left(\vec{q}\right) = -\log{\pi\left(\vec{q}\right)}$ and kinetic
        energy $K\left(\vec{p}\right) = \frac{1}{2} \vec{p}^T \mat{M} \vec{p}$,
        where $\mat{M}$ is a positive-definite matrix that is interpreted as
        the particle's mass.
    The system's dynamics are described by Hamilton's equations,
        \begin{align}
            \frac{\dd \vec{q}}{\dd t} &= \frac{\partial H}{\partial \vec{p}} \\
            \frac{\dd \vec{p}}{\dd t} &= -\frac{\partial H}{\partial \vec{q}},
        \end{align}
        which are integrated to find the state at a particular time.
    Typically this integration is achieved numerically using the leapfrog
        method, a symplectic integrator~\cite{Nea11}.
    I use $\op{L}\left\{\vec{q},\vec{p}\right\}$ to denote an operator that
        maps the state at time~$t$ to the state at time~$t + \epsilon L$, as
        approximated by $L$~leapfrog steps with stepsize~$\epsilon$.
    Additionally, the momentum flip operator gives
        $\op{F}\left\{\vec{q},\vec{p}\right\}
         = \left\{\vec{q},-\vec{p}\right\}$.
    With the $\op{L}$ and $\op{F}$ operators we can reach a discrete set of
        states along an energy contour (subject only to errors in numerical
        integration) and therefore the maximum potential energy (i.e., minimum
        probability density) contour that is reachable is dictated by the
        kinetic energy of the system.
    To guarantee ergodicity of the Markov chain, the momentum is randomised
        after each iteration of the algorithm by
    \begin{equation}
        \op{R}\left\{\vec{q},\vec{p}\right\} =
        \left\{\vec{q}, \sqrt{1-\alpha}\vec{p} + \sqrt{\alpha}\vec{n}\right\},
        \vec{n} \sim \norm\left(\vec{0}, \mat{M}\right).
    \end{equation}

    \begin{algorithm}
        \caption{A single iteration of the \acl{HMC} algorithm that uses
                 Hamiltonian dynamics to make the proposal and the Metropolis
                 criterion to accept or reject it.}
        \begin{algorithmic}[1]
        \Function {HamiltonUpdate}{$\left\{\vec{q},\vec{p}\right\}$}
            \State $\left\{\vec{q}^\prime, \vec{p}^\prime\right\}
                \leftarrow \op{F}\op{L}\left\{\vec{q},\vec{p}\right\}$
            \State $a \leftarrow \min\left(1,
                \exp\left(
                    H\left(\vec{q}, \vec{p}\right) - H\left(\vec{q}^\prime,
                        \vec{p}^\prime\right)\right)\right)$
            \State $\left\{\vec{q},\vec{p}\right\} \leftarrow
                \begin{cases}
                    \left\{\vec{q}^\prime, \vec{p}^\prime\right\}
                        & \text{with probability } a \\
                    \left\{\vec{q},\vec{p}\right\}
                        & \text{with probability } 1 - a
                \end{cases}$
            \State $\left\{\vec{q},\vec{p}\right\} \leftarrow
                        \op{R}\op{F}\left\{\vec{q},\vec{p}\right\}$
            \State \Return $\left\{\vec{q},\vec{p}\right\}$
        \EndFunction
        \end{algorithmic}
    \end{algorithm}

    I implemented the described \ac{HMC} algorithm in a fork of
        BEAST~v1.8~\cite{Dru+12}.

    To enable evaluation of the gradient, I introduced a
        \texttt{Differentiable} interface that defines a method
        \texttt{differentiate()} that returns the gradient with respect to a
        variable.
    The existing \texttt{Likelihood} interface was then modified to extend
        \texttt{Differentiable}.
    The source code for my fork is freely available under version 3 of the GNU
        General Public License at
        \url{https://github.com/armanbilge/B3/tree/hamilton}.

    \subsection*{Results and Discussion}

    \printbibliography

\end{document}
